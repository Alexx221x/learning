{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Convolutional Networks (FCN)\n",
    "Notes from Udacity's Self-Driving Car Nanodegree\n",
    "- Encoder extracts features that the decoder uses layer\n",
    "\n",
    "Pieces:\n",
    "- Pre-train encoder on VGG/ResNet\n",
    "- Do a 1x1 convolution\n",
    "- Tansposed convolutions to upsample\n",
    "\n",
    "Skip connections are added. If VGG is used then only 3rd and 4th pooling layers are used as skip connections. Too many skip connections can lead to an explosion of the model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Replace Fully Connected (FC) with 1x1 convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom init with the seed set to 0 by default\n",
    "def custom_init(shape, dtype=tf.float32, partition_info=None, seed=0):\n",
    "    return tf.random_normal(shape, dtype=dtype, seed=seed)\n",
    "\n",
    "# TODO: Use `tf.layers.conv2d` to reproduce the result of `tf.layers.dense`.\n",
    "# Set the `kernel_size` and `stride`.\n",
    "def conv_1x1(x, num_outputs):\n",
    "    kernel_size = 1\n",
    "    stride = 1\n",
    "    return tf.layers.conv2d(x, num_outputs, kernel_size, stride, kernel_initializer=custom_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense Output = [[[[ 0.08041782 -0.42397892]\n",
      "   [-0.45524108  2.40012264]]\n",
      "\n",
      "  [[-0.14200903  0.7487002 ]\n",
      "   [ 0.38274264 -2.01789618]]]]\n",
      "Conv 1x1 Output = [[[[ 0.08041782 -0.42397892]\n",
      "   [-0.45524108  2.40012264]]\n",
      "\n",
      "  [[-0.14200903  0.7487002 ]\n",
      "   [ 0.38274264 -2.01789618]]]]\n",
      "Same output? = True\n"
     ]
    }
   ],
   "source": [
    "num_outputs = 2\n",
    "x = tf.constant(np.random.randn(1, 2, 2, 1), dtype=tf.float32)\n",
    "# `tf.layers.dense` flattens the input tensor if the rank > 2 and reshapes it back to the original rank\n",
    "# as the output.\n",
    "dense_out = tf.layers.dense(x, num_outputs, kernel_initializer=custom_init)\n",
    "conv_out = conv_1x1(x, num_outputs)\n",
    "\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    a = sess.run(dense_out)\n",
    "    b = sess.run(conv_out)\n",
    "    print(\"Dense Output =\", a)\n",
    "    print(\"Conv 1x1 Output =\", b)\n",
    "\n",
    "    print(\"Same output? =\", np.allclose(a, b, atol=1.e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 2, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Upsampling through transposed convolution\n",
    "- Reverse convolution in which forward and backward passes are swapped\n",
    "- aka deconvolution\n",
    "- Differentiability retained and training exactly the same as before\n",
    "- https://dspguru.com/dsp/faqs/multirate/interpolation/\n",
    "- https://github.com/vdumoulin/conv_arithmetic\n",
    "<img src=\"https://d17h27t6h515a5.cloudfront.net/topher/2017/October/59d8670c_transposed-conv/transposed-conv.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 4, 4, 3)\n",
      "Output Shape: (1, 8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "def upsample(x):\n",
    "    \"\"\"\n",
    "    Apply a two times upsample on x and return the result.\n",
    "    :x: 4-Rank Tensor\n",
    "    :return: TF Operation\n",
    "    \"\"\"\n",
    "    # TODO: Use `tf.layers.conv2d_transpose`\n",
    "    \n",
    "    return tf.layers.conv2d_transpose(x,\n",
    "                                      x.shape[3],\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      strides=2,\n",
    "                                      padding='SAME')\n",
    "\n",
    "\n",
    "x = tf.constant(np.random.randn(1, 4, 4, 3), dtype=tf.float32)\n",
    "conv = upsample(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(conv)\n",
    "\n",
    "    print('Input Shape: {}'.format(x.get_shape()))\n",
    "    print('Output Shape: {}'.format(result.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Skip connection\n",
    "- Retrain information\n",
    "- Use info from multiple resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Segmentation\n",
    "- Bounding boxes for object detection, easier than segmentation\n",
    "    - [YOLO](https://pjreddie.com/darknet/yolo/) and [SSD](https://github.com/balancap/SSD-Tensorflow) which work well:\n",
    "        - High frames per second (FPS)\n",
    "        - Can detect cars, people, traffic signs, etc\n",
    "        \n",
    "- Semantic segmentation\n",
    "    - Pixel level\n",
    "    - Scene understanding\n",
    "    - Multiple decoders for different tasks (e.g. segmentation, depth)\n",
    "    \n",
    "#### Intersection over Union (IoU)\n",
    "- Intersection => TP\n",
    "- Union => classified T (TP + FP) + actually T (TP + FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TensorFlow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.array(\n",
    "    [[0, 0, 0, 0],\n",
    "     [1, 1, 1, 1],\n",
    "     [2, 2, 2, 2],\n",
    "     [3, 3, 3, 3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "prediction = np.array([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 0, 0, 1],\n",
    "    [1, 2, 2, 1],\n",
    "    [3, 3, 0, 3]\n",
    "])\n",
    "\n",
    "def iou1(truth, pred):\n",
    "    t = truth + 1\n",
    "    p = pred + 1\n",
    "    classes = np.unique(t)\n",
    "    \n",
    "    a = ((t == p) *  t).flatten()\n",
    "    tp = Counter(a[a > 0])\n",
    "    b = ((t != p) * t).flatten()\n",
    "    fn = Counter(b[b > 0])\n",
    "    c = ((t != p) * p).flatten()\n",
    "    fp = Counter(c[c > 0])\n",
    "    \n",
    "    ious = {\n",
    "        class_: tp.get(class_) / count\n",
    "        for class_, count in (tp + fp + fn).items()\n",
    "    }\n",
    "    \n",
    "    print(ious)\n",
    "    return sum(ious.values()) / len(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.5714285714285714, 2: 0.3333333333333333, 3: 0.5, 4: 0.75}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5386904761904762"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou1(truth, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU = 0.53869\n"
     ]
    }
   ],
   "source": [
    "def mean_iou(ground_truth, prediction, num_classes):\n",
    "    # TODO: Use `tf.metrics.mean_iou` to compute the mean IoU.\n",
    "    iou, iou_op = tf.metrics.mean_iou(ground_truth,\n",
    "                                      prediction,\n",
    "                                      num_classes)\n",
    "    return iou, iou_op\n",
    "\n",
    "\n",
    "ground_truth = tf.constant([\n",
    "    [0, 0, 0, 0], \n",
    "    [1, 1, 1, 1], \n",
    "    [2, 2, 2, 2], \n",
    "    [3, 3, 3, 3]], dtype=tf.float32)\n",
    "prediction = tf.constant([\n",
    "    [0, 0, 0, 0], \n",
    "    [1, 0, 0, 1], \n",
    "    [1, 2, 2, 1], \n",
    "    [3, 3, 0, 3]], dtype=tf.float32)\n",
    "    \n",
    "# TODO: use `mean_iou` to compute the mean IoU\n",
    "iou, iou_op = mean_iou(ground_truth, prediction, 4)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        # need to initialize local variables for this to run `tf.metrics.mean_iou`\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        \n",
    "        sess.run(iou_op)\n",
    "        # should be 0.53869\n",
    "        print(\"Mean IoU =\", sess.run(iou))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FCN-8\n",
    "https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf\n",
    "https://github.com/udacity/CarND-Object-Detection-Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
